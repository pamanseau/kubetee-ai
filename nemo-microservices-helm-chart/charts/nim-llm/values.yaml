## @section Deployment parameters
## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
## @param affinity [object] [default: {}] Affinity settings for deployment.
affinity: {}

## @param containerSecurityContext [object] Sets privilege and access control settings for container (Only affects the main container, not pod-level).
containerSecurityContext: {}
  # seLinuxOptions: null
  # runAsUser: 1001
  # runAsGroup: 1001
  # runAsNonRoot: true
  # privileged: false
  # readOnlyRootFilesystem: false
  # allowPrivilegeEscalation: false
  # capabilities:
  #   drop:
  #     - ALL
  # seccompProfile:
  #   type: "RuntimeDefault"

## @param customCommand [array] Overrides command line options sent to the NIM with the array listed here.
## For advanced use if necessary only
customCommand: []

## @param customArgs [array] Overrides command line arguments of the NIM container with the array listed here.
## For advanced use if necessary only
customArgs: []

## @param env [array] Adds arbitrary environment variables to the main container.
env: []
# - name: OPENBLAS_NUM_THREADS
#   value: "1"
# - name: POD_NAME
#   valueFrom:
#     fieldRef:
#       fieldPath: metadata.name

## @param extraVolumes [object] Adds arbitrary additional volumes to the deployment set definition.
extraVolumes: {}
  # my-volume-name:
  #   emptyDir: {}

## @param extraVolumeMounts [object] Adds volume mounts to the main container from `extraVolumes`.
extraVolumeMounts: {}
  # my-volume-name:
  #   mountPath: /mnt/myvolume

## @param image.repository [string] Specifies the NIM-LLM Image to deploy.
## @param image.tag [string] Specifies the image tag or version.
## @param image.pullPolicy [string] Sets the image pull policy.
image:
  repository: nvcr.io/nim/meta/llama3-8b-instruct
  pullPolicy: IfNotPresent
  # Tag overrides the image tag whose default is the chart appVersion.
  tag: ""

## @extra imagePullSecrets Specifies a list of secret names that are needed for the main container and any init containers.
## @skip imagePullSecrets[0].name
imagePullSecrets:
  - name: ngc-secret  # change this to whatever your image pull secret should be

## @extra initContainers [object] Specifies model init containers, if needed.
## @param initContainers.extraInit [array] Fully specify any additional init containers your use case requires.
initContainers:
  extraInit: [] # Add any additional init containers your use case requires.
  # -  # full init container definition here

## @param nodeSelector [object] Sets node selectors for the NIM -- for example `nvidia.com/gpu.present: "true"`.
nodeSelector: {}  # likely best to set this to `nvidia.com/gpu.present: "true"` depending on cluster setup

## @param podAnnotations [object] Sets additional annotations on the main deployment pods.
podAnnotations: {}

## @extra podSecurityContext Specifies security context settings for pod.
## @param podSecurityContext.runAsUser Specify user UID for pod.
## @param podSecurityContext.runAsGroup Specify group ID for pod.
## @param podSecurityContext.fsGroup Specify file system owner group id.
podSecurityContext:
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000

## @extra proxyCA [object] Specify a certificate for a custom proxy. When `proxyCA` is set native TLS is used for downloading from NGC.
## @param proxyCA.enabled Specify true if NIM is run behind a proxy.
## @param proxyCA.secretName [nullable] Specify a name of the Kubernetes secret containing the certificate. The secret is created before the deployment. Must be used together with `proxyCA.keyName`
## @param proxyCA.keyName [nullable] Specify a name of the key inside the secret which contains the certificate. Must be used together with `proxyCA.secretName`
proxyCA:
  enabled: false
  secretName: ""
  keyName: ""

## @param replicaCount Specify static replica count for deployment.
replicaCount: 1

## @extra resources [object] Specify resources limits and requests for the running service.
## @param resources.limits.nvidia.com/gpu Specify number of GPUs to present to the running service.
resources:
  limits:
    nvidia.com/gpu: 1  # Number of GPUs to present to the running service

## @extra serviceAccount Options to specify service account for the deployment.
## @param serviceAccount.create Specifies whether a service account should be created.
## @param serviceAccount.annotations [object] Sets annotations to be added to the service account.
## @param serviceAccount.name Specifies the name of the service account to use. If it is not set and create is `true`, a name is generated using a `fullname` template.
serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is `true`, a name is generated using the `fullname` template
  name: ""

## @param statefulSet.enabled Enables `statefulset` deployment. Enabling `statefulSet` allows PVC templates for scaling. If using central PVC with RWX `accessMode`, this isn't needed.
statefulSet:
  enabled: true

## @extra tolerations Specify tolerations for pod assignment. Allows the scheduler to schedule pods with matching taints.
## @skip tolerations[0].key
## @skip tolerations[0].operator
## @skip tolerations[0].effect
tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"


## @section Autoscaling parameters
## @descriptionStart
## Values used for creating a `Horizontal Pod Autoscaler`. If autoscaling is not enabled, the rest are ignored.
## NVIDIA recommends usage of the custom metrics API, commonly implemented with the Prometheus Adapter.
## Standard metrics of CPU and memory are of limited use in scaling NIM.
## @descriptionEnd
## @param autoscaling.enabled Enables horizontal pod autoscaler.
## @param autoscaling.minReplicas Specify minimum replicas for autoscaling.
## @param autoscaling.maxReplicas Specify maximum replicas for autoscaling.
## @param autoscaling.metrics Array of metrics for autoscaling.
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 10
  metrics: []


## @section Ingress parameters
## @param ingress.enabled Enables ingress.
## @param ingress.className Specify class name for Ingress.
## @param ingress.annotations Specify additional annotations for ingress.
## @extra ingress.hosts Specify list of hosts each containing lists of paths.
## @param ingress.hosts[0].host Specify name of host.
## @param ingress.hosts[0].paths[0].path Specify ingress path.
## @param ingress.hosts[0].paths[0].pathType Specify path type.
## @param ingress.hosts[0].paths[0].serviceType Specify service type. It can be can be `nemo` or `openai` -- make sure your model serves the appropriate port(s).
## @param ingress.tls Specify list of pairs of TLS `secretName` and hosts.
ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
          serviceType: openai  # can be nemo or openai -- make sure your model serves the appropriate port(s)

  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local


## @section Probe parameters
## @param livenessProbe.enabled Enables `livenessProbe``.
## @param livenessProbe.method `LivenessProbe` `http` or `script`, but no script is currently provided.
## @param livenessProbe.command `LivenessProbe`` script command to use (unsupported at this time).
## @param livenessProbe.path `LivenessProbe`` endpoint path.
## @param livenessProbe.initialDelaySeconds Initial delay seconds for `livenessProbe`.
## @param livenessProbe.timeoutSeconds Timeout seconds for `livenessProbe`.
## @param livenessProbe.periodSeconds Period seconds for `livenessProbe`.
## @param livenessProbe.successThreshold Success threshold for `livenessProbe`.
## @param livenessProbe.failureThreshold Failure threshold for `livenessProbe`.
livenessProbe:
  enabled: true
  method: http
  command:
    - myscript.sh
  path: /v1/health/live  # correct for LLM container
  initialDelaySeconds: 15
  timeoutSeconds: 1
  periodSeconds: 10
  successThreshold: 1
  failureThreshold: 3

## @param readinessProbe.enabled Enables `readinessProbe`.
## @param readinessProbe.path Readiness Endpoint Path.
## @param readinessProbe.initialDelaySeconds Initial delay seconds for `readinessProbe`.
## @param readinessProbe.timeoutSeconds Timeout seconds for `readinessProbe`.
## @param readinessProbe.periodSeconds Period seconds for `readinessProbe`.
## @param readinessProbe.successThreshold Success threshold for `readinessProbe`.
## @param readinessProbe.failureThreshold Failure threshold for `readinessProbe`.
readinessProbe:
  enabled: true
  path: /v1/health/ready  # correct for LLM container
  initialDelaySeconds: 15
  timeoutSeconds: 1
  periodSeconds: 10
  successThreshold: 1
  failureThreshold: 3

## @param startupProbe.enabled Enables `startupProbe`.
## @param startupProbe.path `StartupProbe` Endpoint Path.
## @param startupProbe.initialDelaySeconds Initial delay seconds for `startupProbe`.
## @param startupProbe.timeoutSeconds Timeout seconds for `startupProbe`.
## @param startupProbe.periodSeconds Period seconds for `startupProbe`.
## @param startupProbe.successThreshold Success threshold for `startupProbe`.
## @param startupProbe.failureThreshold Failure threshold for `startupProbe`.
startupProbe:
  enabled: true
  path: /v1/health/ready  # correct for LLM container
  initialDelaySeconds: 40
  timeoutSeconds: 1
  periodSeconds: 10
  successThreshold: 1
  failureThreshold: 180


## @section Metrics parameters
## @extra metrics
## @extra metrics.serviceMonitor Options for `serviceMonitor` to use the Prometheus Operator and the primary service object.
## @param metrics.serviceMonitor.enabled Enables `serviceMonitor` creation.
## @param metrics.serviceMonitor.additionalLabels [object] Specify additional labels for `serviceMonitor`.
metrics:
  serviceMonitor:  # for use with the Prometheus Operator and the primary service object
    enabled: false
    additionalLabels: {}


## @section Models parameters
## @param model.nimCache [string] Path to mount writeable storage or pre-filled model cache for the NIM.
## @param model.name Specifies the name of the model in the API (usually, the name of the NIM). This is mostly used for helm tests and is usually otherwise optional. This must match the name from _/v1/models_ to allow `helm test <release-name>` to work.
## @param model.ngcAPISecret [string] Name of pre-existing secret with a key named `NGC_API_KEY` that contains an API key for NGC model downloads.
## @param model.ngcAPIKey [string] NGC API key literal to use as the API secret and image pull secret when set.
## @param model.hfTokenSecret [string] Name of pre-existing secret with a key named `HF_TOKEN` that contains a token for HuggingFace model downloads.
## @param model.openaiPort Specifies the Open AI API Port.
## @param model.labels [object] Specifies extra labels to be added on deployed pods.
## @param model.jsonLogging Turn JSON lines logging on or off. Defaults to true.
## @param model.logLevel Log level of NIM service. Possible values of the variable are TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL.
model:
  nimCache: /model-store
  name: meta/llama3-8b-instruct # optional name of the model in the OpenAI API -- used in `helm test`
  ngcAPISecret: "ngc-api"
  ngcAPIKey: ""
  hfTokenSecret: ""
  openaiPort: 8000
  labels: {}  # any extra labels desired on deployed pods
  jsonLogging: true
  logLevel: INFO

## @section Storage parameters
## @extra persistence Specify settings to modify the behavior and use of persistent volumes for model weights.
## @param persistence.enabled Enables the use of persistent volumes.
## @param persistence.existingClaim Specifies an existing persistent volume claim. If using `existingClaim`, run only one replica or use a `ReadWriteMany` storage setup.
## @param persistence.storageClass [nullable] Specifies the persistent volume storage class. If set to `"-"`, this disables dynamic provisioning. If left undefined or set to null, the cluster default storage provisioner is used.
## @param persistence.accessMode Specify `accessMode`. If using an NFS or similar setup, you can use `ReadWriteMany`.
## @param persistence.stsPersistentVolumeClaimRetentionPolicy.whenDeleted Specifies persistent volume claim retention policy when deleted. Only used with Stateful Set volume templates.
## @param persistence.stsPersistentVolumeClaimRetentionPolicy.whenScaled Specifies persistent volume claim retention policy when scaled. Only used with Stateful Set volume templates.
## @param persistence.size Specifies the size of the persistent volume claim (for example 40Gi).
## @param persistence.annotations [object] Adds annotations to the persistent volume claim.
persistence:
  enabled: false
  existingClaim: ""  # if using existingClaim, run only one replica or use a `ReadWriteMany` storage setup
  # Persistent Volume Storage Class
  # If defined, storageClassName: <storageClass>
  # If set to "-", storageClassName: "", which disables dynamic provisioning.
  # If undefined (the default) or set to null, no storageClassName spec is
  #   set, choosing the default provisioner.
  storageClass: ""
  accessMode: ReadWriteOnce  # If using an NFS or similar setup, you can use `ReadWriteMany`
  stsPersistentVolumeClaimRetentionPolicy:
    whenDeleted: Retain
    whenScaled: Retain
  size: 50Gi  # size of claim in bytes (for example 8Gi)
  annotations: {}

## @extra hostPath Configures model cache on local disk on the nodes using `hostPath` -- for special cases. You should understand the security implications before using this option.
## @param hostPath.enabled Enable `hostPath`.
## @param hostPath.path Specifies path on the node used as a `hostPath` volume.
hostPath:
  enabled: false
  path: /model-store

## @extra nfs Configures the model cache to sit on shared direct-mounted NFS. NOTE: you cannot set mount options using direct NFS mount to pods without a node-intalled nfsmount.conf. An NFS-based `PersistentVolumeClaim` is likely better in most cases.
## @param nfs.enabled Enables direct pod NFS mount.
## @param nfs.path Specify path on NFS server to mount.
## @param nfs.server Specify NFS server address.
## @param nfs.readOnly Set to true to mount as read-only.
nfs:
  enabled: false
  server: nfs-server.example.com
  path: /exports
  readOnly: false

## @section Service parameters
## @param service.type Specifies the service type for the deployment.
## @param service.name Overrides the default service name
## @param service.openaiPort Specifies Open AI Port for the service.
## @param service.annotations [object] Specify additional annotations to be added to service.
## @param service.labels Specifies additional labels to be added to service.
service:
  type: ClusterIP
  openaiPort: 8000
  annotations: {}
  labels: {}
  name: ""  # override the default service name


## @section Multi-node parameters
## @descriptionStart
## Large models that must span multiple nodes do not work on plain Kubernetes with the GPU Operator alone at this time.
## Optimized TensorRT profiles, when selected automatically or by environment variable, require one of the following:
##
## - (Recommended) [LeaderWorkerSets](https://github.com/kubernetes-sigs/lws)—We recommend that you use LeaderWorkerSets if your cluster version allows it.
## - (Not recommended) [MPI Operator](https://github.com/kubeflow/mpi-operator)—Since `MPIJob` is a batch-type resource that is not designed with service stability and reliability in mind, this option is not recommended.
## Only optimized profiles are supported for multi-node deployment at this time.
## @descriptionEnd
## @param multiNode.enabled Specify true for multi-node deployments.
## @param multiNode.clusterStartTimeout Set the number of seconds to wait for worker nodes to start before failing.
## @param multiNode.gpusPerNode Number of GPUs for each pod. In most cases, this should match `resources.limits.nvidia.com/gpu`.
## @param multiNode.workers Specifies how many worker pods per multi-node replica to launch.
## @param multiNode.workerCustomCommand Sets a custom command array for the worker nodes in a LeaderWorkerSet only.
## @param multiNode.leaderWorkerSet.enabled True to use `LeaderWorkerSets` for multi-node deployments (recommended). False to `MPIJob` from mpi-operator.
## @param multiNode.existingSSHSecret [string,nullable] Sets the SSH private key for MPI to an existing secret. Otherwise, the Helm chart generates a key randomly during installation.
## @param multiNode.mpiJob.workerAnnotations Annotations only applied to workers for `MPIJob`, if used. This may be necessary to ensure the workers connect to `CNI`s offered by `multus` and the network operator, if used.
## @param multiNode.mpiJob.launcherResources Resources section to apply only to the launcher pods in `MPIJob`, if used. Launchers do not get the chart resources restrictions. Only workers do, since they require GPUs.
## @param multiNode.optimized.enabled True to enable optimized multi-node deployments. Currently, true is the only option.
multiNode:
  clusterStartTimeout: 300
  enabled: false
  workers: 1
  workerCustomCommand: []
  leaderWorkerSet:
    enabled: true
  existingSSHSecret: ""
  mpiJob:
    workerAnnotations: {}
    launcherResources: {}
  gpusPerNode: 1
  optimized:
    enabled: true
